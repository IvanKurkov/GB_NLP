{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfodePkj3jEa"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5156,
     "status": "ok",
     "timestamp": 1619789089261,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "CNvjhDyAKk3U",
    "outputId": "3166c525-fc56-4fd1-92b2-2f1ac4ac18a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-02-16 16:48:55--  http://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15011848 (14M) [application/zip]\n",
      "Saving to: 'rus-eng.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 5,26K 46m15s\n",
      "    50K .......... .......... .......... .......... ..........  0% 8,97K 36m34s\n",
      "   100K .......... .......... .......... .......... ..........  1% 12,4K 30m49s\n",
      "   150K .......... .......... .......... .......... ..........  1% 12,3K 27m57s\n",
      "   200K .......... .......... .......... .......... ..........  1% 12,7K 26m3s\n",
      "   250K .......... .......... .......... .......... ..........  2% 27,1K 23m6s\n",
      "   300K .......... .......... .......... .......... ..........  2% 15,6K 21m56s\n",
      "   350K .......... .......... .......... .......... ..........  2% 19,4K 20m39s\n",
      "   400K .......... .......... .......... .......... ..........  3% 16,6K 19m52s\n",
      "   450K .......... .......... .......... .......... ..........  3% 10,6K 20m3s\n",
      "   500K .......... .......... .......... .......... ..........  3% 21,8K 19m8s\n",
      "   550K .......... .......... .......... .......... ..........  4% 41,8K 17m57s\n",
      "   600K .......... .......... .......... .......... ..........  4% 60,3K 16m48s\n",
      "   650K .......... .......... .......... .......... ..........  4% 64,3K 15m48s\n",
      "   700K .......... .......... .......... .......... ..........  5% 82,1K 14m53s\n",
      "   750K .......... .......... .......... .......... ..........  5%  159K 14m0s\n",
      "   800K .......... .......... .......... .......... ..........  5%  156K 13m13s\n",
      "   850K .......... .......... .......... .......... ..........  6%  192K 12m30s\n",
      "   900K .......... .......... .......... .......... ..........  6%  241K 11m51s\n",
      "   950K .......... .......... .......... .......... ..........  6%  240K 11m16s\n",
      "  1000K .......... .......... .......... .......... ..........  7%  251K 10m44s\n",
      "  1050K .......... .......... .......... .......... ..........  7%  310K 10m14s\n",
      "  1100K .......... .......... .......... .......... ..........  7%  522K 9m47s\n",
      "  1150K .......... .......... .......... .......... ..........  8%  303K 9m22s\n",
      "  1200K .......... .......... .......... .......... ..........  8%  376K 8m59s\n",
      "  1250K .......... .......... .......... .......... ..........  8%  661K 8m37s\n",
      "  1300K .......... .......... .......... .......... ..........  9%  327K 8m18s\n",
      "  1350K .......... .......... .......... .......... ..........  9%  921K 7m58s\n",
      "  1400K .......... .......... .......... .......... ..........  9%  379K 7m41s\n",
      "  1450K .......... .......... .......... .......... .......... 10%  670K 7m25s\n",
      "  1500K .......... .......... .......... .......... .......... 10%  568K 7m10s\n",
      "  1550K .......... .......... .......... .......... .......... 10%  450K 6m56s\n",
      "  1600K .......... .......... .......... .......... .......... 11% 4,45M 6m42s\n",
      "  1650K .......... .......... .......... .......... .......... 11%  330K 6m29s\n",
      "  1700K .......... .......... .......... .......... .......... 11%  947K 6m17s\n",
      "  1750K .......... .......... .......... .......... .......... 12%  570K 6m6s\n",
      "  1800K .......... .......... .......... .......... .......... 12%  741K 5m55s\n",
      "  1850K .......... .......... .......... .......... .......... 12%  954K 5m45s\n",
      "  1900K .......... .......... .......... .......... .......... 13%  572K 5m35s\n",
      "  1950K .......... .......... .......... .......... .......... 13%  745K 5m26s\n",
      "  2000K .......... .......... .......... .......... .......... 13%  960K 5m17s\n",
      "  2050K .......... .......... .......... .......... .......... 14%  570K 5m9s\n",
      "  2100K .......... .......... .......... .......... .......... 14% 1,06M 5m1s\n",
      "  2150K .......... .......... .......... .......... .......... 15%  768K 4m53s\n",
      "  2200K .......... .......... .......... .......... .......... 15% 4,68M 4m45s\n",
      "  2250K .......... .......... .......... .......... .......... 15%  574K 4m39s\n",
      "  2300K .......... .......... .......... .......... .......... 16% 1,06M 4m32s\n",
      "  2350K .......... .......... .......... .......... .......... 16%  766K 4m25s\n",
      "  2400K .......... .......... .......... .......... .......... 16% 5,19M 4m19s\n",
      "  2450K .......... .......... .......... .......... .......... 17%  578K 4m13s\n",
      "  2500K .......... .......... .......... .......... .......... 17% 1,06M 4m7s\n",
      "  2550K .......... .......... .......... .......... .......... 17%  779K 4m2s\n",
      "  2600K .......... .......... .......... .......... .......... 18% 5,00M 3m56s\n",
      "  2650K .......... .......... .......... .......... .......... 18%  583K 3m51s\n",
      "  2700K .......... .......... .......... .......... .......... 18% 1,06M 3m47s\n",
      "  2750K .......... .......... .......... .......... .......... 19% 2,08M 3m42s\n",
      "  2800K .......... .......... .......... .......... .......... 19% 1012K 3m37s\n",
      "  2850K .......... .......... .......... .......... .......... 19% 11,3M 3m32s\n",
      "  2900K .......... .......... .......... .......... .......... 20%  586K 3m28s\n",
      "  2950K .......... .......... .......... .......... .......... 20% 1,07M 3m24s\n",
      "  3000K .......... .......... .......... .......... .......... 20% 2,10M 3m20s\n",
      "  3050K .......... .......... .......... .......... .......... 21% 1024K 3m16s\n",
      "  3100K .......... .......... .......... .......... .......... 21% 11,3M 3m12s\n",
      "  3150K .......... .......... .......... .......... .......... 21%  586K 3m9s\n",
      "  3200K .......... .......... .......... .......... .......... 22% 1,08M 3m5s\n",
      "  3250K .......... .......... .......... .......... .......... 22% 2,16M 3m2s\n",
      "  3300K .......... .......... .......... .......... .......... 22% 1,11M 2m58s\n",
      "  3350K .......... .......... .......... .......... .......... 23% 5,78M 2m55s\n",
      "  3400K .......... .......... .......... .......... .......... 23%  956K 2m52s\n",
      "  3450K .......... .......... .......... .......... .......... 23% 1,31M 2m49s\n",
      "  3500K .......... .......... .......... .......... .......... 24% 1,10M 2m46s\n",
      "  3550K .......... .......... .......... .......... .......... 24% 2,18M 2m43s\n",
      "  3600K .......... .......... .......... .......... .......... 24% 1,02M 2m40s\n",
      "  3650K .......... .......... .......... .......... .......... 25% 11,3M 2m37s\n",
      "  3700K .......... .......... .......... .......... .......... 25%  975K 2m34s\n",
      "  3750K .......... .......... .......... .......... .......... 25% 1,32M 2m32s\n",
      "  3800K .......... .......... .......... .......... .......... 26% 1,10M 2m29s\n",
      "  3850K .......... .......... .......... .......... .......... 26% 2,21M 2m27s\n",
      "  3900K .......... .......... .......... .......... .......... 26% 1,12M 2m24s\n",
      "  3950K .......... .......... .......... .......... .......... 27% 6,38M 2m22s\n",
      "  4000K .......... .......... .......... .......... .......... 27% 9,64M 2m19s\n",
      "  4050K .......... .......... .......... .......... .......... 27%  591K 2m17s\n",
      "  4100K .......... .......... .......... .......... .......... 28% 1,17M 2m15s\n",
      "  4150K .......... .......... .......... .......... .......... 28% 2,13M 2m13s\n",
      "  4200K .......... .......... .......... .......... .......... 28% 1,14M 2m11s\n",
      "  4250K .......... .......... .......... .......... .......... 29% 5,29M 2m9s\n",
      "  4300K .......... .......... .......... .......... .......... 29% 6,90M 2m7s\n",
      "  4350K .......... .......... .......... .......... .......... 30% 5,75M 2m5s\n",
      "  4400K .......... .......... .......... .......... .......... 30%  665K 2m3s\n",
      "  4450K .......... .......... .......... .......... .......... 30% 1,17M 2m1s\n",
      "  4500K .......... .......... .......... .......... .......... 31% 2,21M 1m59s\n",
      "  4550K .......... .......... .......... .......... .......... 31% 7,21M 1m57s\n",
      "  4600K .......... .......... .......... .......... .......... 31% 1,22M 1m55s\n",
      "  4650K .......... .......... .......... .......... .......... 32% 4,35M 1m54s\n",
      "  4700K .......... .......... .......... .......... .......... 32% 8,35M 1m52s\n",
      "  4750K .......... .......... .......... .......... .......... 32%  647K 1m50s\n",
      "  4800K .......... .......... .......... .......... .......... 33% 8,28M 1m49s\n",
      "  4850K .......... .......... .......... .......... .......... 33% 1,10M 1m47s\n",
      "  4900K .......... .......... .......... .......... .......... 33% 2,65M 1m46s\n",
      "  4950K .......... .......... .......... .......... .......... 34% 1,18M 1m44s\n",
      "  5000K .......... .......... .......... .......... .......... 34% 6,07M 1m42s\n",
      "  5050K .......... .......... .......... .......... .......... 34% 7,37M 1m41s\n",
      "  5100K .......... .......... .......... .......... .......... 35% 8,23M 99s\n",
      "  5150K .......... .......... .......... .......... .......... 35%  652K 98s\n",
      "  5200K .......... .......... .......... .......... .......... 35% 8,89M 97s\n",
      "  5250K .......... .......... .......... .......... .......... 36% 1,10M 95s\n",
      "  5300K .......... .......... .......... .......... .......... 36% 2,86M 94s\n",
      "  5350K .......... .......... .......... .......... .......... 36% 1,16M 93s\n",
      "  5400K .......... .......... .......... .......... .......... 37% 11,6M 91s\n",
      "  5450K .......... .......... .......... .......... .......... 37% 5,03M 90s\n",
      "  5500K .......... .......... .......... .......... .......... 37% 11,3M 89s\n",
      "  5550K .......... .......... .......... .......... .......... 38% 1,06M 88s\n",
      "  5600K .......... .......... .......... .......... .......... 38% 1,35M 86s\n",
      "  5650K .......... .......... .......... .......... .......... 38% 8,21M 85s\n",
      "  5700K .......... .......... .......... .......... .......... 39% 1,13M 84s\n",
      "  5750K .......... .......... .......... .......... .......... 39% 2,87M 83s\n",
      "  5800K .......... .......... .......... .......... .......... 39% 1,16M 82s\n",
      "  5850K .......... .......... .......... .......... .......... 40% 13,5M 81s\n",
      "  5900K .......... .......... .......... .......... .......... 40% 5,38M 79s\n",
      "  5950K .......... .......... .......... .......... .......... 40% 11,5M 78s\n",
      "  6000K .......... .......... .......... .......... .......... 41% 1,07M 77s\n",
      "  6050K .......... .......... .......... .......... .......... 41% 1,35M 76s\n",
      "  6100K .......... .......... .......... .......... .......... 41% 11,0M 75s\n",
      "  6150K .......... .......... .......... .......... .......... 42% 1,22M 74s\n",
      "  6200K .......... .......... .......... .......... .......... 42% 2,40M 73s\n",
      "  6250K .......... .......... .......... .......... .......... 42% 10,8M 72s\n",
      "  6300K .......... .......... .......... .......... .......... 43% 1,16M 71s\n",
      "  6350K .......... .......... .......... .......... .......... 43% 6,47M 70s\n",
      "  6400K .......... .......... .......... .......... .......... 43% 11,6M 69s\n",
      "  6450K .......... .......... .......... .......... .......... 44% 9,71M 68s\n",
      "  6500K .......... .......... .......... .......... .......... 44% 1,11M 67s\n",
      "  6550K .......... .......... .......... .......... .......... 45% 1,34M 67s\n",
      "  6600K .......... .......... .......... .......... .......... 45% 11,8M 66s\n",
      "  6650K .......... .......... .......... .......... .......... 45% 1,14M 65s\n",
      "  6700K .......... .......... .......... .......... .......... 46% 2,96M 64s\n",
      "  6750K .......... .......... .......... .......... .......... 46% 11,5M 63s\n",
      "  6800K .......... .......... .......... .......... .......... 46% 1,16M 62s\n",
      "  6850K .......... .......... .......... .......... .......... 47% 11,2M 61s\n",
      "  6900K .......... .......... .......... .......... .......... 47% 7,64M 61s\n",
      "  6950K .......... .......... .......... .......... .......... 47% 10,7M 60s\n",
      "  7000K .......... .......... .......... .......... .......... 48% 1,11M 59s\n",
      "  7050K .......... .......... .......... .......... .......... 48% 1,34M 58s\n",
      "  7100K .......... .......... .......... .......... .......... 48% 11,1M 58s\n",
      "  7150K .......... .......... .......... .......... .......... 49% 1,25M 57s\n",
      "  7200K .......... .......... .......... .......... .......... 49% 6,64M 56s\n",
      "  7250K .......... .......... .......... .......... .......... 49% 3,04M 55s\n",
      "  7300K .......... .......... .......... .......... .......... 50% 11,4M 55s\n",
      "  7350K .......... .......... .......... .......... .......... 50% 1,17M 54s\n",
      "  7400K .......... .......... .......... .......... .......... 50% 8,18M 53s\n",
      "  7450K .......... .......... .......... .......... .......... 51% 11,3M 52s\n",
      "  7500K .......... .......... .......... .......... .......... 51% 11,3M 52s\n",
      "  7550K .......... .......... .......... .......... .......... 51% 1,12M 51s\n",
      "  7600K .......... .......... .......... .......... .......... 52% 1,35M 50s\n",
      "  7650K .......... .......... .......... .......... .......... 52% 11,3M 50s\n",
      "  7700K .......... .......... .......... .......... .......... 52% 11,3M 49s\n",
      "  7750K .......... .......... .......... .......... .......... 53% 1,19M 48s\n",
      "  7800K .......... .......... .......... .......... .......... 53% 3,08M 48s\n",
      "  7850K .......... .......... .......... .......... .......... 53%  236K 47s\n",
      "  7900K .......... .......... .......... .......... .......... 54%  156M 47s\n",
      "  7950K .......... .......... .......... .......... .......... 54%  238M 46s\n",
      "  8000K .......... .......... .......... .......... .......... 54%  428M 45s\n",
      "  8050K .......... .......... .......... .......... .......... 55%  327M 45s\n",
      "  8100K .......... .......... .......... .......... .......... 55%  240M 44s\n",
      "  8150K .......... .......... .......... .......... .......... 55%  330M 44s\n",
      "  8200K .......... .......... .......... .......... .......... 56%  327M 43s\n",
      "  8250K .......... .......... .......... .......... .......... 56%  207M 42s\n",
      "  8300K .......... .......... .......... .......... .......... 56%  304M 42s\n",
      "  8350K .......... .......... .......... .......... .......... 57%  340M 41s\n",
      "  8400K .......... .......... .......... .......... .......... 57%  426M 41s\n",
      "  8450K .......... .......... .......... .......... .......... 57%  211M 40s\n",
      "  8500K .......... .......... .......... .......... .......... 58% 1,18M 40s\n",
      "  8550K .......... .......... .......... .......... .......... 58% 8,68M 39s\n",
      "  8600K .......... .......... .......... .......... .......... 59% 8,30M 38s\n",
      "  8650K .......... .......... .......... .......... .......... 59% 6,58M 38s\n",
      "  8700K .......... .......... .......... .......... .......... 59%  663K 37s\n",
      "  8750K .......... .......... .......... .......... .......... 60% 8,35M 37s\n",
      "  8800K .......... .......... .......... .......... .......... 60% 1,15M 36s\n",
      "  8850K .......... .......... .......... .......... .......... 60% 2,83M 36s\n",
      "  8900K .......... .......... .......... .......... .......... 61% 1,12M 35s\n",
      "  8950K .......... .......... .......... .......... .......... 61% 8,09M 35s\n",
      "  9000K .......... .......... .......... .......... .......... 61% 9,02M 34s\n",
      "  9050K .......... .......... .......... .......... .......... 62% 8,63M 34s\n",
      "  9100K .......... .......... .......... .......... .......... 62% 1,06M 33s\n",
      "  9150K .......... .......... .......... .......... .......... 62% 1,35M 33s\n",
      "  9200K .......... .......... .......... .......... .......... 63% 7,76M 33s\n",
      "  9250K .......... .......... .......... .......... .......... 63% 1,18M 32s\n",
      "  9300K .......... .......... .......... .......... .......... 63% 2,79M 32s\n",
      "  9350K .......... .......... .......... .......... .......... 64% 1,13M 31s\n",
      "  9400K .......... .......... .......... .......... .......... 64% 7,90M 31s\n",
      "  9450K .......... .......... .......... .......... .......... 64% 9,98M 30s\n",
      "  9500K .......... .......... .......... .......... .......... 65% 7,53M 30s\n",
      "  9550K .......... .......... .......... .......... .......... 65% 1,08M 29s\n",
      "  9600K .......... .......... .......... .......... .......... 65% 1,36M 29s\n",
      "  9650K .......... .......... .......... .......... .......... 66% 7,37M 29s\n",
      "  9700K .......... .......... .......... .......... .......... 66% 1,20M 28s\n",
      "  9750K .......... .......... .......... .......... .......... 66% 2,77M 28s\n",
      "  9800K .......... .......... .......... .......... .......... 67% 1,13M 27s\n",
      "  9850K .......... .......... .......... .......... .......... 67% 8,18M 27s\n",
      "  9900K .......... .......... .......... .......... .......... 67% 11,3M 26s\n",
      "  9950K .......... .......... .......... .......... .......... 68% 7,37M 26s\n",
      " 10000K .......... .......... .......... .......... .......... 68% 1,08M 26s\n",
      " 10050K .......... .......... .......... .......... .......... 68% 1,38M 25s\n",
      " 10100K .......... .......... .......... .......... .......... 69% 7,57M 25s\n",
      " 10150K .......... .......... .......... .......... .......... 69% 1,19M 25s\n",
      " 10200K .......... .......... .......... .......... .......... 69% 2,85M 24s\n",
      " 10250K .......... .......... .......... .......... .......... 70% 10,0M 24s\n",
      " 10300K .......... .......... .......... .......... .......... 70% 1,11M 23s\n",
      " 10350K .......... .......... .......... .......... .......... 70% 11,4M 23s\n",
      " 10400K .......... .......... .......... .......... .......... 71% 8,64M 23s\n",
      " 10450K .......... .......... .......... .......... .......... 71% 9,38M 22s\n",
      " 10500K .......... .......... .......... .......... .......... 71%  652K 22s\n",
      " 10550K .......... .......... .......... .......... .......... 72% 12,0M 22s\n",
      " 10600K .......... .......... .......... .......... .......... 72% 1,22M 21s\n",
      " 10650K .......... .......... .......... .......... .......... 72% 7,17M 21s\n",
      " 10700K .......... .......... .......... .......... .......... 73% 2,68M 20s\n",
      " 10750K .......... .......... .......... .......... .......... 73% 1,16M 20s\n",
      " 10800K .......... .......... .......... .......... .......... 74% 8,10M 20s\n",
      " 10850K .......... .......... .......... .......... .......... 74% 11,5M 19s\n",
      " 10900K .......... .......... .......... .......... .......... 74% 9,33M 19s\n",
      " 10950K .......... .......... .......... .......... .......... 75% 7,71M 19s\n",
      " 11000K .......... .......... .......... .......... .......... 75%  666K 18s\n",
      " 11050K .......... .......... .......... .......... .......... 75% 11,4M 18s\n",
      " 11100K .......... .......... .......... .......... .......... 76% 1,23M 18s\n",
      " 11150K .......... .......... .......... .......... .......... 76% 7,16M 17s\n",
      " 11200K .......... .......... .......... .......... .......... 76% 2,80M 17s\n",
      " 11250K .......... .......... .......... .......... .......... 77% 1,14M 17s\n",
      " 11300K .......... .......... .......... .......... .......... 77% 9,18M 16s\n",
      " 11350K .......... .......... .......... .......... .......... 77% 11,3M 16s\n",
      " 11400K .......... .......... .......... .......... .......... 78% 9,74M 16s\n",
      " 11450K .......... .......... .......... .......... .......... 78% 7,77M 16s\n",
      " 11500K .......... .......... .......... .......... .......... 78%  667K 15s\n",
      " 11550K .......... .......... .......... .......... .......... 79% 11,3M 15s\n",
      " 11600K .......... .......... .......... .......... .......... 79% 1,22M 15s\n",
      " 11650K .......... .......... .......... .......... .......... 79% 7,74M 14s\n",
      " 11700K .......... .......... .......... .......... .......... 80% 2,81M 14s\n",
      " 11750K .......... .......... .......... .......... .......... 80% 1,14M 14s\n",
      " 11800K .......... .......... .......... .......... .......... 80% 8,62M 13s\n",
      " 11850K .......... .......... .......... .......... .......... 81% 11,3M 13s\n",
      " 11900K .......... .......... .......... .......... .......... 81% 11,0M 13s\n",
      " 11950K .......... .......... .......... .......... .......... 81% 10,5M 13s\n",
      " 12000K .......... .......... .......... .......... .......... 82%  652K 12s\n",
      " 12050K .......... .......... .......... .......... .......... 82% 11,5M 12s\n",
      " 12100K .......... .......... .......... .......... .......... 82% 9,71M 12s\n",
      " 12150K .......... .......... .......... .......... .......... 83% 1,21M 11s\n",
      " 12200K .......... .......... .......... .......... .......... 83% 2,75M 11s\n",
      " 12250K .......... .......... .......... .......... .......... 83% 11,3M 11s\n",
      " 12300K .......... .......... .......... .......... .......... 84% 1,12M 11s\n",
      " 12350K .......... .......... .......... .......... .......... 84% 10,7M 10s\n",
      " 12400K .......... .......... .......... .......... .......... 84% 11,3M 10s\n",
      " 12450K .......... .......... .......... .......... .......... 85% 11,3M 10s\n",
      " 12500K .......... .......... .......... .......... .......... 85% 1,06M 10s\n",
      " 12550K .......... .......... .......... .......... .......... 85% 1,39M 9s\n",
      " 12600K .......... .......... .......... .......... .......... 86% 11,3M 9s\n",
      " 12650K .......... .......... .......... .......... .......... 86% 1,22M 9s\n",
      " 12700K .......... .......... .......... .......... .......... 86% 9,23M 9s\n",
      " 12750K .......... .......... .......... .......... .......... 87% 2,76M 8s\n",
      " 12800K .......... .......... .......... .......... .......... 87% 1,14M 8s\n",
      " 12850K .......... .......... .......... .......... .......... 87% 9,93M 8s\n",
      " 12900K .......... .......... .......... .......... .......... 88% 11,4M 8s\n",
      " 12950K .......... .......... .......... .......... .......... 88% 11,0M 7s\n",
      " 13000K .......... .......... .......... .......... .......... 89% 11,3M 7s\n",
      " 13050K .......... .......... .......... .......... .......... 89% 1,07M 7s\n",
      " 13100K .......... .......... .......... .......... .......... 89% 1,38M 7s\n",
      " 13150K .......... .......... .......... .......... .......... 90% 11,3M 6s\n",
      " 13200K .......... .......... .......... .......... .......... 90% 1,23M 6s\n",
      " 13250K .......... .......... .......... .......... .......... 90% 2,64M 6s\n",
      " 13300K .......... .......... .......... .......... .......... 91% 11,4M 6s\n",
      " 13350K .......... .......... .......... .......... .......... 91% 1,16M 5s\n",
      " 13400K .......... .......... .......... .......... .......... 91% 10,2M 5s\n",
      " 13450K .......... .......... .......... .......... .......... 92% 11,3M 5s\n",
      " 13500K .......... .......... .......... .......... .......... 92% 11,3M 5s\n",
      " 13550K .......... .......... .......... .......... .......... 92% 7,88M 4s\n",
      " 13600K .......... .......... .......... .......... .......... 93%  663K 4s\n",
      " 13650K .......... .......... .......... .......... .......... 93% 12,1M 4s\n",
      " 13700K .......... .......... .......... .......... .......... 93% 10,9M 4s\n",
      " 13750K .......... .......... .......... .......... .......... 94% 1,24M 4s\n",
      " 13800K .......... .......... .......... .......... .......... 94% 2,65M 3s\n",
      " 13850K .......... .......... .......... .......... .......... 94% 11,4M 3s\n",
      " 13900K .......... .......... .......... .......... .......... 95% 1,16M 3s\n",
      " 13950K .......... .......... .......... .......... .......... 95% 11,0M 3s\n",
      " 14000K .......... .......... .......... .......... .......... 95% 11,3M 2s\n",
      " 14050K .......... .......... .......... .......... .......... 96% 11,3M 2s\n",
      " 14100K .......... .......... .......... .......... .......... 96% 7,82M 2s\n",
      " 14150K .......... .......... .......... .......... .......... 96%  663K 2s\n",
      " 14200K .......... .......... .......... .......... .......... 97% 11,6M 2s\n",
      " 14250K .......... .......... .......... .......... .......... 97% 11,3M 1s\n",
      " 14300K .......... .......... .......... .......... .......... 97% 1,25M 1s\n",
      " 14350K .......... .......... .......... .......... .......... 98% 2,65M 1s\n",
      " 14400K .......... .......... .......... .......... .......... 98% 11,2M 1s\n",
      " 14450K .......... .......... .......... .......... .......... 98% 1,16M 1s\n",
      " 14500K .......... .......... .......... .......... .......... 99% 10,2M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 99% 12,7M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 99% 11,3M 0s\n",
      " 14650K ..........                                            100% 11,2M=58s\n",
      "\n",
      "2023-02-16 16:49:56 (254 KB/s) - 'rus-eng.zip' saved [15011848/15011848]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1813,
     "status": "ok",
     "timestamp": 1619789098992,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "83bg17Lr-7XK",
    "outputId": "91ec0134-b351-4d0a-c8ac-215affefed97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"unzip\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!mkdir rus-eng\n",
    "!unzip rus-eng.zip -d rus-eng/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1619789101916,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "7o5L92efMMhf",
    "outputId": "6ac53232-05f5-449b-8cfc-e0dda693d57f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!ls /content/rus-eng/ -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kRVATYOgJs1b"
   },
   "outputs": [],
   "source": [
    "# Download the file\n",
    "path_to_file = \"rus-eng/rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rd0jw-eC3jEh"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "  w = w.lower().strip()\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1619789112313,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "yV9lZXQXNbnH",
    "outputId": "2f509965-ecec-4988-cffa-09ab9f954f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> i can't go . <end>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(\"I can't go.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENG, RUS]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12954,
     "status": "ok",
     "timestamp": 1619808083270,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "cTbSbBz55QtF",
    "outputId": "5a5b0b4e-da16-4483-8e56-5e07fd79f0bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> go . <end>\n",
      "<start> марш ! <end>\n"
     ]
    }
   ],
   "source": [
    "en, ru = create_dataset(path_to_file, None)\n",
    "print(en[0])\n",
    "print(ru[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bIOn8RCNDJXG"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eAY9k49G3jE_"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOi42V79Ydlr"
   },
   "source": [
    "### Limit the size of the dataset to experiment faster (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1074,
     "status": "ok",
     "timestamp": 1619789980135,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "C8j9g9AnIeZV",
    "outputId": "510da3ec-5a6d-49b9-a0da-29c693f1aec5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451436, 451436)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en), len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cnxC7q-j3jFD"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1619790003654,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "4QILQkOs3jFG",
    "outputId": "ddc672e5-2231-4985-b550-2dbddd4468b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lJPmLZGMeD5q"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1619790005935,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "VXukARTDd7MT",
    "outputId": "a3606064-f48d-4e81-94d5-9c30d5e90ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "8 ----> это\n",
      "15366 ----> леопард\n",
      "5 ----> ?\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "8 ----> is\n",
      "18 ----> that\n",
      "9 ----> a\n",
      "5956 ----> leopard\n",
      "6 ----> ?\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 500\n",
    "units = 2024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1279,
     "status": "ok",
     "timestamp": 1619790037553,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "qc6-NK1GtWQt",
    "outputId": "5f42bae2-eefc-492f-f5c5-ad5215d549cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 15]), TensorShape([256, 11]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=False,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27335,
     "status": "ok",
     "timestamp": 1619790133885,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "60gSVh05Jl6l",
    "outputId": "4eaa568c-966c-4a9b-895d-4d5e22d20e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Hidden state shape: (batch size, units) (256, 2024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "P5UY8wko3jFp"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 955,
     "status": "ok",
     "timestamp": 1619791577723,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "XKcypC0AGeLR",
    "outputId": "6f51f5ef-6d92-4933-d202-e2d512cbba37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 7335])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sample_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1619791547930,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "6y0HF-zMF_vp",
    "outputId": "69a0893f-61c6-40c5-bce6-5911c3c4355b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 2024])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sample_h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_nmt_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10943081,
     "status": "ok",
     "timestamp": 1619803077637,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "ddefjBMa3jF0",
    "outputId": "b54245db-e06a-46b0-edc0-fab6afaba17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.7288\n",
      "Epoch 1 Batch 100 Loss 1.7682\n",
      "Epoch 1 Batch 200 Loss 1.4790\n",
      "Epoch 1 Batch 300 Loss 1.1995\n",
      "Epoch 1 Loss 1.6698\n",
      "Time taken for 1 epoch 49.354281425476074 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1668\n",
      "Epoch 2 Batch 100 Loss 1.0227\n",
      "Epoch 2 Batch 200 Loss 0.8969\n",
      "Epoch 2 Batch 300 Loss 0.8673\n",
      "Epoch 2 Loss 0.9793\n",
      "Time taken for 1 epoch 38.56188368797302 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.7247\n",
      "Epoch 3 Batch 100 Loss 0.6896\n",
      "Epoch 3 Batch 200 Loss 0.6649\n",
      "Epoch 3 Batch 300 Loss 0.5736\n",
      "Epoch 3 Loss 0.6557\n",
      "Time taken for 1 epoch 36.70270562171936 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4275\n",
      "Epoch 4 Batch 100 Loss 0.4540\n",
      "Epoch 4 Batch 200 Loss 0.3975\n",
      "Epoch 4 Batch 300 Loss 0.3906\n",
      "Epoch 4 Loss 0.4218\n",
      "Time taken for 1 epoch 38.392359018325806 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2830\n",
      "Epoch 5 Batch 100 Loss 0.2866\n",
      "Epoch 5 Batch 200 Loss 0.3072\n",
      "Epoch 5 Batch 300 Loss 0.3035\n",
      "Epoch 5 Loss 0.2712\n",
      "Time taken for 1 epoch 36.783775806427 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1801\n",
      "Epoch 6 Batch 100 Loss 0.1786\n",
      "Epoch 6 Batch 200 Loss 0.1873\n",
      "Epoch 6 Batch 300 Loss 0.1786\n",
      "Epoch 6 Loss 0.1841\n",
      "Time taken for 1 epoch 38.35591650009155 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1209\n",
      "Epoch 7 Batch 100 Loss 0.1248\n",
      "Epoch 7 Batch 200 Loss 0.1292\n",
      "Epoch 7 Batch 300 Loss 0.1345\n",
      "Epoch 7 Loss 0.1349\n",
      "Time taken for 1 epoch 36.710566997528076 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0990\n",
      "Epoch 8 Batch 100 Loss 0.1090\n",
      "Epoch 8 Batch 200 Loss 0.1262\n",
      "Epoch 8 Batch 300 Loss 0.1257\n",
      "Epoch 8 Loss 0.1078\n",
      "Time taken for 1 epoch 38.415876150131226 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0728\n",
      "Epoch 9 Batch 100 Loss 0.0827\n",
      "Epoch 9 Batch 200 Loss 0.0922\n",
      "Epoch 9 Batch 300 Loss 0.0888\n",
      "Epoch 9 Loss 0.0922\n",
      "Time taken for 1 epoch 36.75270700454712 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0694\n",
      "Epoch 10 Batch 100 Loss 0.0713\n",
      "Epoch 10 Batch 200 Loss 0.0740\n",
      "Epoch 10 Batch 300 Loss 0.0901\n",
      "Epoch 10 Loss 0.0830\n",
      "Time taken for 1 epoch 38.53518533706665 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0600\n",
      "Epoch 11 Batch 100 Loss 0.0647\n",
      "Epoch 11 Batch 200 Loss 0.0826\n",
      "Epoch 11 Batch 300 Loss 0.0957\n",
      "Epoch 11 Loss 0.0781\n",
      "Time taken for 1 epoch 36.8086097240448 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0641\n",
      "Epoch 12 Batch 100 Loss 0.0612\n",
      "Epoch 12 Batch 200 Loss 0.0603\n",
      "Epoch 12 Batch 300 Loss 0.0946\n",
      "Epoch 12 Loss 0.0748\n",
      "Time taken for 1 epoch 38.49550819396973 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0513\n",
      "Epoch 13 Batch 100 Loss 0.0657\n",
      "Epoch 13 Batch 200 Loss 0.0758\n",
      "Epoch 13 Batch 300 Loss 0.0965\n",
      "Epoch 13 Loss 0.0736\n",
      "Time taken for 1 epoch 37.1032817363739 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0494\n",
      "Epoch 14 Batch 100 Loss 0.0735\n",
      "Epoch 14 Batch 200 Loss 0.0721\n",
      "Epoch 14 Batch 300 Loss 0.0935\n",
      "Epoch 14 Loss 0.0726\n",
      "Time taken for 1 epoch 39.18933463096619 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0557\n",
      "Epoch 15 Batch 100 Loss 0.0661\n",
      "Epoch 15 Batch 200 Loss 0.0887\n",
      "Epoch 15 Batch 300 Loss 0.0655\n",
      "Epoch 15 Loss 0.0715\n",
      "Time taken for 1 epoch 37.28389072418213 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0520\n",
      "Epoch 16 Batch 100 Loss 0.0683\n",
      "Epoch 16 Batch 200 Loss 0.0626\n",
      "Epoch 16 Batch 300 Loss 0.0743\n",
      "Epoch 16 Loss 0.0701\n",
      "Time taken for 1 epoch 38.99882888793945 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0635\n",
      "Epoch 17 Batch 100 Loss 0.0625\n",
      "Epoch 17 Batch 200 Loss 0.0636\n",
      "Epoch 17 Batch 300 Loss 0.0781\n",
      "Epoch 17 Loss 0.0687\n",
      "Time taken for 1 epoch 37.280487298965454 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0457\n",
      "Epoch 18 Batch 100 Loss 0.0748\n",
      "Epoch 18 Batch 200 Loss 0.0680\n",
      "Epoch 18 Batch 300 Loss 0.0675\n",
      "Epoch 18 Loss 0.0662\n",
      "Time taken for 1 epoch 38.89613389968872 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0447\n",
      "Epoch 19 Batch 100 Loss 0.0516\n",
      "Epoch 19 Batch 200 Loss 0.0759\n",
      "Epoch 19 Batch 300 Loss 0.0580\n",
      "Epoch 19 Loss 0.0639\n",
      "Time taken for 1 epoch 37.24209761619568 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0751\n",
      "Epoch 20 Batch 100 Loss 0.0493\n",
      "Epoch 20 Batch 200 Loss 0.0578\n",
      "Epoch 20 Batch 300 Loss 0.0725\n",
      "Epoch 20 Loss 0.0633\n",
      "Time taken for 1 epoch 38.946714639663696 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0529\n",
      "Epoch 21 Batch 100 Loss 0.0635\n",
      "Epoch 21 Batch 200 Loss 0.0680\n",
      "Epoch 21 Batch 300 Loss 0.0584\n",
      "Epoch 21 Loss 0.0622\n",
      "Time taken for 1 epoch 37.354902029037476 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0574\n",
      "Epoch 22 Batch 100 Loss 0.0512\n",
      "Epoch 22 Batch 200 Loss 0.0635\n",
      "Epoch 22 Batch 300 Loss 0.0726\n",
      "Epoch 22 Loss 0.0609\n",
      "Time taken for 1 epoch 38.928452491760254 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0361\n",
      "Epoch 23 Batch 100 Loss 0.0683\n",
      "Epoch 23 Batch 200 Loss 0.0671\n",
      "Epoch 23 Batch 300 Loss 0.0838\n",
      "Epoch 23 Loss 0.0589\n",
      "Time taken for 1 epoch 37.31538939476013 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0481\n",
      "Epoch 24 Batch 100 Loss 0.0509\n",
      "Epoch 24 Batch 200 Loss 0.0671\n",
      "Epoch 24 Batch 300 Loss 0.0676\n",
      "Epoch 24 Loss 0.0574\n",
      "Time taken for 1 epoch 38.86899161338806 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0531\n",
      "Epoch 25 Batch 100 Loss 0.0555\n",
      "Epoch 25 Batch 200 Loss 0.0547\n",
      "Epoch 25 Batch 300 Loss 0.0719\n",
      "Epoch 25 Loss 0.0563\n",
      "Time taken for 1 epoch 37.37042236328125 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0549\n",
      "Epoch 26 Batch 100 Loss 0.0597\n",
      "Epoch 26 Batch 200 Loss 0.0639\n",
      "Epoch 26 Batch 300 Loss 0.0569\n",
      "Epoch 26 Loss 0.0549\n",
      "Time taken for 1 epoch 38.954583168029785 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0486\n",
      "Epoch 27 Batch 100 Loss 0.0492\n",
      "Epoch 27 Batch 200 Loss 0.0468\n",
      "Epoch 27 Batch 300 Loss 0.0683\n",
      "Epoch 27 Loss 0.0539\n",
      "Time taken for 1 epoch 37.29306650161743 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0492\n",
      "Epoch 28 Batch 100 Loss 0.0580\n",
      "Epoch 28 Batch 200 Loss 0.0600\n",
      "Epoch 28 Batch 300 Loss 0.0573\n",
      "Epoch 28 Loss 0.0537\n",
      "Time taken for 1 epoch 39.09883117675781 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0554\n",
      "Epoch 29 Batch 100 Loss 0.0471\n",
      "Epoch 29 Batch 200 Loss 0.0505\n",
      "Epoch 29 Batch 300 Loss 0.0513\n",
      "Epoch 29 Loss 0.0520\n",
      "Time taken for 1 epoch 37.283961057662964 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0462\n",
      "Epoch 30 Batch 100 Loss 0.0465\n",
      "Epoch 30 Batch 200 Loss 0.0464\n",
      "Epoch 30 Batch 300 Loss 0.0608\n",
      "Epoch 30 Loss 0.0512\n",
      "Time taken for 1 epoch 38.974310874938965 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0500\n",
      "Epoch 31 Batch 100 Loss 0.0493\n",
      "Epoch 31 Batch 200 Loss 0.0347\n",
      "Epoch 31 Batch 300 Loss 0.0705\n",
      "Epoch 31 Loss 0.0505\n",
      "Time taken for 1 epoch 37.48722767829895 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0536\n",
      "Epoch 32 Batch 100 Loss 0.0446\n",
      "Epoch 32 Batch 200 Loss 0.0561\n",
      "Epoch 32 Batch 300 Loss 0.0487\n",
      "Epoch 32 Loss 0.0491\n",
      "Time taken for 1 epoch 41.0474488735199 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0370\n",
      "Epoch 33 Batch 100 Loss 0.0351\n",
      "Epoch 33 Batch 200 Loss 0.0552\n",
      "Epoch 33 Batch 300 Loss 0.0570\n",
      "Epoch 33 Loss 0.0488\n",
      "Time taken for 1 epoch 37.91372895240784 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0425\n",
      "Epoch 34 Batch 100 Loss 0.0515\n",
      "Epoch 34 Batch 200 Loss 0.0581\n",
      "Epoch 34 Batch 300 Loss 0.0678\n",
      "Epoch 34 Loss 0.0482\n",
      "Time taken for 1 epoch 39.03501582145691 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0355\n",
      "Epoch 35 Batch 100 Loss 0.0431\n",
      "Epoch 35 Batch 200 Loss 0.0534\n",
      "Epoch 35 Batch 300 Loss 0.0587\n",
      "Epoch 35 Loss 0.0472\n",
      "Time taken for 1 epoch 36.915783405303955 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0525\n",
      "Epoch 36 Batch 100 Loss 0.0406\n",
      "Epoch 36 Batch 200 Loss 0.0463\n",
      "Epoch 36 Batch 300 Loss 0.0669\n",
      "Epoch 36 Loss 0.0466\n",
      "Time taken for 1 epoch 38.522438764572144 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0458\n",
      "Epoch 37 Batch 100 Loss 0.0383\n",
      "Epoch 37 Batch 200 Loss 0.0430\n",
      "Epoch 37 Batch 300 Loss 0.0425\n",
      "Epoch 37 Loss 0.0455\n",
      "Time taken for 1 epoch 36.74423408508301 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0362\n",
      "Epoch 38 Batch 100 Loss 0.0360\n",
      "Epoch 38 Batch 200 Loss 0.0471\n",
      "Epoch 38 Batch 300 Loss 0.0459\n",
      "Epoch 38 Loss 0.0452\n",
      "Time taken for 1 epoch 38.386789321899414 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0340\n",
      "Epoch 39 Batch 100 Loss 0.0462\n",
      "Epoch 39 Batch 200 Loss 0.0519\n",
      "Epoch 39 Batch 300 Loss 0.0482\n",
      "Epoch 39 Loss 0.0451\n",
      "Time taken for 1 epoch 36.709768772125244 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0359\n",
      "Epoch 40 Batch 100 Loss 0.0408\n",
      "Epoch 40 Batch 200 Loss 0.0403\n",
      "Epoch 40 Batch 300 Loss 0.0536\n",
      "Epoch 40 Loss 0.0446\n",
      "Time taken for 1 epoch 39.56069016456604 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0418\n",
      "Epoch 41 Batch 100 Loss 0.0367\n",
      "Epoch 41 Batch 200 Loss 0.0462\n",
      "Epoch 41 Batch 300 Loss 0.0515\n",
      "Epoch 41 Loss 0.0434\n",
      "Time taken for 1 epoch 37.10713052749634 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0264\n",
      "Epoch 42 Batch 100 Loss 0.0513\n",
      "Epoch 42 Batch 200 Loss 0.0407\n",
      "Epoch 42 Batch 300 Loss 0.0536\n",
      "Epoch 42 Loss 0.0421\n",
      "Time taken for 1 epoch 38.37411904335022 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0392\n",
      "Epoch 43 Batch 100 Loss 0.0478\n",
      "Epoch 43 Batch 200 Loss 0.0466\n",
      "Epoch 43 Batch 300 Loss 0.0443\n",
      "Epoch 43 Loss 0.0410\n",
      "Time taken for 1 epoch 36.96945834159851 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0348\n",
      "Epoch 44 Batch 100 Loss 0.0350\n",
      "Epoch 44 Batch 200 Loss 0.0381\n",
      "Epoch 44 Batch 300 Loss 0.0455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss 0.0412\n",
      "Time taken for 1 epoch 40.53286671638489 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0318\n",
      "Epoch 45 Batch 100 Loss 0.0378\n",
      "Epoch 45 Batch 200 Loss 0.0445\n",
      "Epoch 45 Batch 300 Loss 0.0480\n",
      "Epoch 45 Loss 0.0407\n",
      "Time taken for 1 epoch 37.44020652770996 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0274\n",
      "Epoch 46 Batch 100 Loss 0.0313\n",
      "Epoch 46 Batch 200 Loss 0.0649\n",
      "Epoch 46 Batch 300 Loss 0.0389\n",
      "Epoch 46 Loss 0.0406\n",
      "Time taken for 1 epoch 40.435800313949585 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0324\n",
      "Epoch 47 Batch 100 Loss 0.0321\n",
      "Epoch 47 Batch 200 Loss 0.0445\n",
      "Epoch 47 Batch 300 Loss 0.0389\n",
      "Epoch 47 Loss 0.0409\n",
      "Time taken for 1 epoch 37.81082892417908 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0305\n",
      "Epoch 48 Batch 100 Loss 0.0383\n",
      "Epoch 48 Batch 200 Loss 0.0427\n",
      "Epoch 48 Batch 300 Loss 0.0406\n",
      "Epoch 48 Loss 0.0409\n",
      "Time taken for 1 epoch 40.21131730079651 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0255\n",
      "Epoch 49 Batch 100 Loss 0.0408\n",
      "Epoch 49 Batch 200 Loss 0.0386\n",
      "Epoch 49 Batch 300 Loss 0.0392\n",
      "Epoch 49 Loss 0.0396\n",
      "Time taken for 1 epoch 37.496235609054565 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0392\n",
      "Epoch 50 Batch 100 Loss 0.0385\n",
      "Epoch 50 Batch 200 Loss 0.0510\n",
      "Epoch 50 Batch 300 Loss 0.0456\n",
      "Epoch 50 Loss 0.0388\n",
      "Time taken for 1 epoch 38.6823468208313 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1608145599781,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "UJpT9D5_OgP6",
    "outputId": "a5bf709a-7e66-4fd8-aca9-777497144965"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x19a33b59c10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 985,
     "status": "ok",
     "timestamp": 1619808753710,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "WrAM0FDomq3E",
    "outputId": "d366d6cc-cc03-4e35-a65a-9d06dcbfff36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> здесь хорошо . <end>\n",
      "Predicted translation: it's good here . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Здесь хорошо.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1619808761495,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "5bhFfwcIMX5i",
    "outputId": "f89a2d14-a72b-4477-9d76-36837baaefff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> я не смогу поехать . <end>\n",
      "Predicted translation: i can't go . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Я не смогу поехать.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1619808768959,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "zSx2iM36EZQZ",
    "outputId": "42bc96b4-37c0-439f-fff9-224fdc58c527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> вы еще дома ? <end>\n",
      "Predicted translation: are you still at home ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Вы еще дома?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3LLCx3ZE0Ls",
    "outputId": "b64aa087-8232-474e-e3c7-98c186081845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> вы все еще дома ? <end>\n",
      "Predicted translation: are you still home ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Вы все еще дома?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1619808777901,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "DUQVLVqUE1YW",
    "outputId": "6d768ecc-e145-4a4a-b313-0986c44bc1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> попробуй сделать это . <end>\n",
      "Predicted translation: try to do that . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Попробуй сделать это.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1619808783771,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "f09_hUFx9EJh",
    "outputId": "73980799-f0f9-4ff5-835c-ced55d9a4770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> я люблю , когда идет снег . <end>\n",
      "Predicted translation: i like her badly . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Я люблю, когда идет снег.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> я люблю , когда падает снег . <end>\n",
      "Predicted translation: i like her badly lost . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Я люблю, когда падает снег.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7c5p8rmkHQG",
    "outputId": "d4682d71-f778-41f5-e4a9-2e1235976123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> я никогда такого не делаю . <end>\n",
      "Predicted translation: i never do that . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Я никогда такого не делаю.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jdXES85KkTVS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> я хочу поесть мясо . <end>\n",
      "Predicted translation: i want to eat meat . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'Я хочу поесть мясо.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
