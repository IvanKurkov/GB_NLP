{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769dee4e",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "\n",
    "Задание: обучите три классификатора:\n",
    "\n",
    "1) на токенах с высокой частотой\n",
    "\n",
    "2) на токенах со средней частотой\n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "### Задание 2.\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "### Задание 3.\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера\n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2dcb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5431fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = 1\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = 0\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ae7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5775a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d1d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67e9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b89a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb04fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eabc524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca93fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted = sorted(freq_dict.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freq_dict_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_try = freq_dict_sorted[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_try = [x[0] for x in first_try]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), stop_words=first_try)\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cbfba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f127c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_try = freq_dict_sorted[:10000] + freq_dict_sorted[170000:]\n",
    "second_try = [x[0] for x in second_try]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf91f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), stop_words=second_try)\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de373b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_try = freq_dict_sorted[:300000]\n",
    "last_try = [x[0] for x in last_try]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), stop_words=last_try)\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eda894",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e47a5",
   "metadata": {},
   "source": [
    "### Из 350000 уникальных слов взял первые 10000, что показало лучший результат.  Т.е. самые популярные - самые важные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc64f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0accf04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b791af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76     28122\n",
      "           1       0.76      0.77      0.77     28587\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5d3a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat_names = [x[0] for x in list(vec.vocabulary_.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bc97b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in zip(clf.coef_[0], list_feat_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab3fd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features = sorted(features, key=lambda x: -abs(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3103c861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-9.602272534653427, 'entermasha'),\n",
       " (-7.3141490077236355, 'хошь'),\n",
       " (-7.195608518547961, 'juliamayko'),\n",
       " (6.2423015679019835, 'маловат'),\n",
       " (-6.200291415539503, 'обоюдно'),\n",
       " (6.191114222193199, 'kozpwyfi7x'),\n",
       " (-5.634941998342662, 'ушками'),\n",
       " (-5.107528035334031, 'бессоная'),\n",
       " (5.051760399638847, 'тойота'),\n",
       " (5.025289240959661, 'кампания'),\n",
       " (-4.926364291032549, 'гирляндой'),\n",
       " (-4.766811485062593, 'перерыве'),\n",
       " (-4.49097139278457, 'дождуся'),\n",
       " (-4.385022279933267, 'ро'),\n",
       " (-4.1021397895106935, 'e_papunaishvili'),\n",
       " (-4.081108261948567, 'мороженок'),\n",
       " (-4.006814429476276, 'маркетинге'),\n",
       " (-3.9818239537036466, 'неудобно'),\n",
       " (-3.7488203129798348, 'xo'),\n",
       " (-3.6257038035425384, 'вшэ'),\n",
       " (-3.357777204396727, '_stay_sstrong_'),\n",
       " (-3.326990156046736, '8bcunw6sau'),\n",
       " (3.3268571595760403, 'мечтой'),\n",
       " (-3.1982763346255965, 'быв'),\n",
       " (-3.1623195254108087, 'фейм'),\n",
       " (-3.078125734161422, 'nycu1merhi'),\n",
       " (-3.0568658146026446, 'dearpennis_'),\n",
       " (3.019529729880074, 'antonatelatello'),\n",
       " (-3.0136280028716036, 'terekhina_1997'),\n",
       " (-2.9264047315013397, 'переворачивают'),\n",
       " (-2.925747150857234, 'сталлоне'),\n",
       " (-2.891805228774065, 'cooper'),\n",
       " (-2.8750443082346946, 'девой'),\n",
       " (2.8641840944672405, 'камбоджа'),\n",
       " (-2.849373618848536, 'tea_idinarag'),\n",
       " (2.8279349331927253, 'наслушаешься'),\n",
       " (-2.8023190544378536, 'bioothod'),\n",
       " (-2.7944992604841596, 'zinkevichsasha'),\n",
       " (-2.7739993645152565, 'китайская'),\n",
       " (2.7573149769576206, 'bakeeva_liza'),\n",
       " (-2.7269510539825994, 'ход'),\n",
       " (-2.725103036167606, 'vensko_vika'),\n",
       " (-2.6799703347530963, '830wws8r5p'),\n",
       " (-2.678118913601867, 'tatjana_kot'),\n",
       " (-2.6630530825198826, 'лулзов'),\n",
       " (2.6337715455723325, 'kristiolsh'),\n",
       " (2.6269895671104373, 'соседних'),\n",
       " (-2.6263643687020894, 'usj0zvq9p2'),\n",
       " (-2.6095491792507675, 'пишеться'),\n",
       " (-2.600085038616412, 'кексик')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd2255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
